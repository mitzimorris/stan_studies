{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Parameterization choices for hierarchical models:  centered, non-centered\n",
    "\n",
    "### Overview\n",
    "\n",
    "This note expands on the section in Bob Carpenter's most excellent case study\n",
    "[Hierarchical Partial Pooling for Repeated Binary Trials](https://mc-stan.org/users/documentation/case-studies/pool-binary-trials.html) which introduces the non-centered parameterization of a hierarchical model.\n",
    "\n",
    "Hierarchical models provide partial pooling of information across parameters\n",
    "according to group membership.\n",
    "The hierarchical model provides group-level parameters\n",
    "which influence the fixed-effects parameters\n",
    "(individual distributions on the group members).\n",
    "For datasets where the groups have relatively few members,\n",
    "MCMC samplers cannot easily explore the resulting sampling density.\n",
    "The non-centered parameterization mitigates this problem by decoupling\n",
    "the group-level and fixed-effects parameters in the sampling distribution.\n",
    "\n",
    "The case study dataset is taken from baseball, consisting of\n",
    "the number of hits and at-bats for a set of Major League Baseball players.\n",
    "While individual players have differing batting abilities, they are taken from the population\n",
    "of MLB baseball players.\n",
    "Therefore, it makes sense to build a hierarchical model of player ability.\n",
    "\n",
    "The data consists of `N` observations `y`, where each observation $y_n$ is\n",
    "the number of successes for ${player}_n$ in `K` trials.\n",
    "The dataset is small:  18 players ($N = 18$), 45 at-bats ($K = 45$).\n",
    "The model estimates ${\\theta}_n$, each player's chance of success for an at-bat.\n",
    "($\\theta * 1000$ is a player's \"batting average\".)\n",
    "It does so by recasting the problem in terms of parameter $\\alpha$,\n",
    "a player's log-odds of success.\n",
    "The hierarchical model puts a normal prior with group-level parameters\n",
    "$\\mu$ and $\\sigma$ on the estimates for parameter $\\alpha$,\n",
    "which pulls the individual player estimates towards the group mean $\\mu$.\n",
    "\n",
    "The log-odds parameterization makes it much easier to expand the model\n",
    "by adding more fixed effects and other multilevel effects.\n",
    "The change of success `theta` is computed in the model's\n",
    "generated quantities block as `inv_logit(alpha)`.\n",
    "\n",
    "The centered parameterization for a hierarchical model corresponds directly to\n",
    "the data structure:   the individual-level parameter `alpha` - a player's log-odds of success\n",
    "is given a prior distribution specified in terms of the group-level parameters:\n",
    "`alpha ~ normal(mu, sigma)`.\n",
    "The non-centered parameterization is recommended for hierarchical models\n",
    "where the groups have relatively few members.\n",
    "The trick is to decouple `alpha`, `mu`, and `sigma` in the sampling distribution\n",
    "by reparameterization.\n",
    "There are two ways to do this reparameterization:\n",
    "\n",
    "- a non-centered parameterization with standard normal prior on parameter `alpha_std` and auxiliary variable `alpha`.\n",
    "- a non-centered parameterization using an affine transform on parameter `alpha`.\n",
    "\n",
    "In this note we show models for each and then plot the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages used in this notebook\n",
    "\n",
    "We use [CmdStanPy](https://mc-stan.org/cmdstanpy) to do the model fitting and plot the results using [plotnine](https://plotnine.readthedocs.io/en/stable/), a ggplot2-like Python package.\n",
    "Pandas and NumPy are also used for data munging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "%matplotlib inline\n",
    "\n",
    "from cmdstanpy import CmdStanModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "theme_set(\n",
    "  theme_grey() + \n",
    "  theme(text=element_text(size=10),\n",
    "        plot_title=element_text(size=14),\n",
    "        axis_title_x=element_text(size=12),\n",
    "        axis_title_y=element_text(size=12),\n",
    "        axis_text_x=element_text(size=8),\n",
    "        axis_text_y=element_text(size=8)\n",
    "       )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseball Data:  Number of hits in 45 at-bats for 18 MLB players in 1971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "comment": "#R_CODE#NA"
   },
   "outputs": [],
   "source": [
    "with open('efron-morris-75-data.tsv') as tsv_file:\n",
    "    df = pd.read_csv(\"efron-morris-75-data.tsv\", sep=\"\\t\")\n",
    "df.style.hide_index().format(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball_data = {\"N\": df.shape[0],\n",
    "                 \"K\": df['At-Bats'],\n",
    "                 \"y\": df['Hits'],\n",
    "                 \"K_new\": df['RemainingAt-Bats'],\n",
    "                 \"y_new\": df['SeasonHits']-df['Hits']}\n",
    "\n",
    "M = 10000  # desired number of draws from the posterior\n",
    "\n",
    "# ggplot2 x_y plot with axis labels and optional title\n",
    "def scatter_plot(df, x_lab, y_lab, title=''):\n",
    "  return (ggplot(df, aes('x', 'y')) +\n",
    "          geom_point(alpha=0.2) +\n",
    "          xlab(x_lab) +\n",
    "          ylab(y_lab) +\n",
    "          ggtitle(title) +\n",
    "          theme(figure_size=(8,6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "The model we are interested in is a hierarchical model\n",
    "with a *normal prior* on the *log odds of success*.\n",
    "The mathematical model specification is\n",
    "\n",
    "$$\n",
    "p(y_n \\, | \\, K_n, \\alpha_n) \n",
    "\\ = \\ \\mathsf{Binomial}(y_n \\, | \\, K_n, \\ \\mathrm{logit}^{-1}(\\alpha_n))\n",
    "$$\n",
    "\n",
    "with a simple normal hierarchical prior\n",
    "\n",
    "$$\n",
    "p(\\alpha_n \\, | \\, \\mu, \\sigma)\n",
    "= \\mathsf{Normal}(\\alpha_n \\, | \\, \\mu, \\sigma).\n",
    "$$\n",
    "\n",
    "a weakly informative hyperprior for $\\mu$\n",
    "\n",
    "$$\n",
    "p(\\mu) = \\mathsf{Normal}(\\mu \\, | \\, -1, 1),\n",
    "$$\n",
    "\n",
    "and a half normal prior on $\\sigma$\n",
    "\n",
    "$$\n",
    "p(\\sigma)\n",
    "\\ = \\ 2 \\, \\mathsf{Normal}(\\sigma \\, | \\, 0, 1)\n",
    "\\ \\propto \\ \\mathsf{Normal}(\\sigma \\, | \\, 0, 1).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centered Parameterization\n",
    "\n",
    "The Stan program `hier-logit-centered.stan` is a straightforward encoding of\n",
    "a hierarchical model with a normal prior on the log odds of success,\n",
    "but this is not the optimal way to code this model in Stan, as we will soon demonstrate.\n",
    "\n",
    "```\n",
    "parameters {\n",
    "  real mu;                       // population mean of success log-odds\n",
    "  real<lower=0> sigma;           // population sd of success log-odds\n",
    "  vector[N] alpha;               // success log-odds\n",
    "}\n",
    "model {\n",
    "  mu ~ normal(-1, 1);               // hyperprior\n",
    "  sigma ~ normal(0, 1);             // hyperprior\n",
    "  alpha ~ normal(mu, sigma);        // prior (hierarchical)\n",
    "  y ~ binomial_logit(K, alpha);     // likelihood\n",
    "}\n",
    "```\n",
    "\n",
    "The chance of success $\\theta$ is computed as a generated quantity.\n",
    "\n",
    "```\n",
    "generated quantities {\n",
    "  vector[N] theta = inv_logit(alpha);\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In CmdStanPy, model fitting is done in two steps:\n",
    "first instantiate the model object from a Stan program file;\n",
    "then run the Stan inference algorithm, here the NUTS-HMC sampler,\n",
    "which returns the inferences.\n",
    "\n",
    "We instantiate the CmdStanModel object from the Stan program file 'hier-logit-centered.stan'.\n",
    "By default, CmdStanPy compiles the model on object instantiation, unless there is a corresponding\n",
    "exe file which has a more recent timestamp than the source file.\n",
    "The model's `code` method returns the Stan program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hier_logit_centered_model = CmdStanModel(stan_file='hier-logit-centered.stan')\n",
    "print(hier_logit_centered_model.code())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next run the NUTS-HMC sampler.  By default the sampler runs 4 chains.  The argument `iter_sampling` specifies the *per-chain* number of sampling iterations.  The defaults are 1000 warmup and 1000 sampling iterations per chain,\n",
    "for a sample containing a total of 4000 draws.  Since $M = 10000$, we override this default.  We specify the random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_centered = hier_logit_centered_model.sample(\n",
    "    data=baseball_data,\n",
    "    iter_sampling=int(M/4),\n",
    "    seed=54321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `theta` is the per-player chance of success, i.e., `theta * 1000` is a player's batting average.\n",
    "The estimates range from 0.24 to 0.3, batting averages between 240 and a respectable 300, which is in line\n",
    "with what we know about major league baseball players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_centered.summary(sig_figs=3).round(decimals=3).filter(\n",
    "    regex=r'mu|sigma|theta', axis=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reported Eff values for `sigma` are low and the R_hat value is above 1.   CmdStan's `diagnose` method indicates that this model had problems fitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit_centered.diagnose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Funnel\n",
    "\n",
    "These diagnostics indicate that the sampler failed to fit the data and that the resulting sample is not a sample from\n",
    "the true posterior.   The reason for this failure is that given the small amount of data,\n",
    "the sampler cannot properly determine how much of the observed variance in the data is individual-level variance, parameter `alpha`, or group-level variance, parameter `sigma`.\n",
    "The diagnostics report low ESS and poor R-hat for `sigma`.\n",
    "\n",
    "Plotting the estimate of `alpha[1]`, the log-odds success for player 1, against `log(sigma)`,\n",
    "the group-level variance, provide additional evidence of the problem.\n",
    "This plot shows a clear funnel shape with many draws at the bottom of the neck of the funnel.\n",
    "This is the reason for the low EFF numbers for `sigma`.  The sampler \"gets stuck\" at the bottom of the funnel.\n",
    "The algorithm tries to jump to a new point, but large jumps fall outside of the posterior density, resulting in a divergence.  Small jumps fail to exit the neck of the funnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_y = pd.DataFrame(\n",
    "    data={'x': fit_centered.stan_variable('alpha')[:,0],\n",
    "          'y': np.log(fit_centered.stan_variable('sigma'))\n",
    "         }\n",
    ")\n",
    "\n",
    "scatter_plot(df_x_y,\n",
    "         x_lab = \"alpha[1]: player 1 log odds of success\",\n",
    "         y_lab = \"log(sigma): log population scale\",\n",
    "         title = \"hierarchical vs fixed, centered parameterization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Non-Centered Parameterization \n",
    "\n",
    "Instead of a hierarchical prior, \n",
    "the non-centered parameterization takes a standard unit normal prior for a new variable,\n",
    "\n",
    "$$\n",
    "\\alpha^{\\mathrm{std}}_n = \\frac{\\alpha_n - \\mu}{\\sigma}.\n",
    "$$\n",
    "\n",
    "Then we can parameterize in terms of $\\alpha^{\\mathrm{std}}$, which\n",
    "has a standard-normal distribution\n",
    "\n",
    "$$\n",
    "p(\\alpha^{\\mathrm{std}}_n) = \\mathsf{Normal}(\\alpha^{\\mathrm{std}}_n \\, | \\, 0, 1).\n",
    "$$\n",
    "\n",
    "We can then define our original $\\alpha$ as a derived quantity.\n",
    "\n",
    "$$\n",
    "\\alpha_n = \\mu + \\sigma \\, \\alpha^{\\mathrm{std}}_n.\n",
    "$$\n",
    "\n",
    "This decouples the sampling distribution\n",
    "for $\\alpha^{\\mathrm{std}}$ from $\\mu$ and $\\sigma$, greatly reducing\n",
    "their correlation in the posterior.\n",
    "*The sampler only knows about the model parameters*.\n",
    "Since the prior on parameter $\\alpha$ is not specified in terms of parameters $\\mu$ and $\\sigma$, the sampler can move more freely along their axes, and therefore explore the posterior more fully.\n",
    "Although we decouple the parameters, we still need to share information\n",
    "between the group-level and individual level parameters;\n",
    "this is done using auxiliary variables, either transformed parameters or\n",
    "directly in the model block.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Non-centered parameterization using a standard normal distribution\n",
    "\n",
    "Prior to Stan 2.19, a Stan implementation directly encoded the above reparameterization.\n",
    "This requires 3 changes to the centered parameterization:\n",
    "\n",
    "- In the parameters block, declaring a parameter `alpha_std` (instead of parameter `alpha`).  This name implies that it will have a standard normal distribution.\n",
    "\n",
    "- In the transformed parameters block define variable `alpha` as `mu + sigma * alpha_std`.\n",
    "\n",
    "- In the model block we put a standard normal prior on `alpha_std`, which decouples the sampling distribution of `alpha_std` from `mu` and `sigma`.\n",
    "\n",
    "The Stan program \"hier-logit-nc-std-norm.stan\" follows this pattern.\n",
    "```\n",
    "data {\n",
    "  int<lower=0> N; // items\n",
    "  array[N] int<lower=0> K; // initial trials\n",
    "  array[N] int<lower=0> y; // initial successes\n",
    "}\n",
    "parameters {\n",
    "  real mu; // population mean of success log-odds\n",
    "  real<lower=0> sigma; // population sd of success log-odds\n",
    "  vector[N] alpha_std; // success log-odds (standardized)\n",
    "}\n",
    "transformed parameters {\n",
    "  vector[N] alpha = mu + sigma * alpha_std;\n",
    "}\n",
    "model {\n",
    "  mu ~ normal(-1, 1); // hyperprior\n",
    "  sigma ~ normal(0, 1); // hyperprior\n",
    "  alpha_std ~ normal(0, 1); // prior (hierarchical)\n",
    "  y ~ binomial_logit(K, alpha); // likelihood\n",
    "}\n",
    "generated quantities {\n",
    "  vector[N] theta = inv_logit(alpha);\n",
    "}\n",
    "```\n",
    "\n",
    "###  Non-centered parameterization using an affine transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Stan version 2.19, the Stan language's\n",
    "[affine transform](https://mc-stan.org/docs/reference-manual/univariate-data-types-and-variable-declarations.html) construct provides a more concise way to do this.\n",
    "For a real variable, the affine transform $x\\mapsto \\mu + \\sigma * x$ with offset $\\mu$ and (positive) multiplier $\\sigma$\n",
    "is specified using a syntax like that used for upper/lower bounds, with keywords <code>offset</code>, <code>multiplier</code>.\n",
    "Specifying the affine transform in the parameter declaration for \n",
    "$\\alpha^{\\mathrm{std}}$ eliminates the need for intermediate variables\n",
    "and makes it easier to see the hierarchical structure of the model.\n",
    "\n",
    "When the parameters to the prior for $\\sigma$ are constants, the\n",
    "normalization for the half-prior (compared to the full prior) is\n",
    "constant and therefore does not need to be included in the notation.\n",
    "This only works if the parameters to the density are data or constants;\n",
    "if they are defined as parameters or as quantities depending on parameters,\n",
    "then explicit truncation is required.\n",
    "\n",
    "The Stan program `hier-logit-nc-affine-xform.stan` uses the affine-transform syntax to\n",
    "specify the non-centered version of the hierarchical model\n",
    "with a normal prior on the log odds of success.\n",
    "\n",
    "```\n",
    "data {\n",
    "  int<lower=0> N; // items\n",
    "  array[N] int<lower=0> K; // initial trials\n",
    "  array[N] int<lower=0> y; // initial successes\n",
    "}\n",
    "parameters {\n",
    "  real mu; // population mean of success log-odds\n",
    "  real<lower=0> sigma; // population sd of success log-odds\n",
    "  vector<offset=mu, multiplier=sigma>[N] alpha; // success log-odds (standardized)\n",
    "}\n",
    "model {\n",
    "  mu ~ normal(-1, 1); // hyperprior\n",
    "  sigma ~ normal(0, 1); // hyperprior\n",
    "  alpha ~ normal(mu, sigma); // prior (hierarchical)\n",
    "  y ~ binomial_logit(K, alpha); // likelihood\n",
    "}\n",
    "generated quantities {\n",
    "  vector[N] theta = inv_logit(alpha);\n",
    "  vector[N] alpha_std = (alpha - mu)/sigma;\n",
    "}\n",
    "```\n",
    "\n",
    "### Fitting the standard normal reparameterization\n",
    "\n",
    "The model `hier-logit-nc-std-norm.stan` fits the model using parameter `alpha_std`.\n",
    "\n",
    "*Full disclosure: the choice of random seed '54321' was far from random; this seed allows the sampler to fit the model without divergences.  Other seeds may result in 1 or 2 divergences for a sample of 2500 draws.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_std_norm_model = CmdStanModel(stan_file='hier-logit-nc-std-norm.stan')\n",
    "print(nc_std_norm_model.code())\n",
    "\n",
    "fit_nc_std_norm = nc_std_norm_model.sample(\n",
    "    data=baseball_data,\n",
    "    iter_sampling=int(M/4),\n",
    "    seed=54321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we check for problems by running CmdStan's `diagnose` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit_nc_std_norm.diagnose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimates for `mu`, `sigma`, `theta` and `alpha` are roughly the same as for the centered parameterization.  The non-centered parameterization results in a much larger effective sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Centered parameterization\")\n",
    "print(fit_centered.summary(sig_figs=3).round(decimals=3).filter(\n",
    "    [\"mu\", \"sigma\",\n",
    "     \"theta[1]\", \"theta[5]\", \"theta[10]\", \"theta[18]\",\n",
    "     \"alpha[1]\", \"alpha[5]\", \"alpha[10]\", \"alpha[18]\"],\n",
    "    axis=\"index\"))\n",
    "\n",
    "print(\"\\nNon-centered parameterization, std_normal reparameterization\")\n",
    "print(fit_nc_std_norm.summary(sig_figs=3).round(decimals=3).filter(\n",
    "    [\"mu\", \"sigma\",\n",
    "     \"theta[1]\", \"theta[5]\", \"theta[10]\", \"theta[18]\",\n",
    "     \"alpha[1]\", \"alpha[5]\", \"alpha[10]\", \"alpha[18]\"],\n",
    "    axis=\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To consider how the reparameterization is working, we plot the\n",
    "posterior for the mean and log scale of the hyperprior.\n",
    "The prior location ($\\mu$) and scale ($\\sigma$) are coupled in the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_y = pd.DataFrame(data={'x': fit_nc_std_norm.stan_variable('mu'),\n",
    "                            'y': np.log(fit_nc_std_norm.stan_variable('sigma'))})\n",
    "\n",
    "scatter_plot(df_x_y,\n",
    "         x_lab = \"mu\",\n",
    "         y_lab = \"log(sigma)\",\n",
    "         title = \"Hierarchical params, standard normal reparameterization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we plot the sample values for log scale and the first transformed parameter, `alpha_std[1]`,\n",
    "the range of both the X and Y axis are much wider.  There is a diffuse set of points in the bottom half of the plot, not many points at the bottom of the Y axis.  This indicates that the sampler has been able to properly explore the posterior density and therefore we have a valid sample from the posterior.  As log `sigma` approaches zero the plot has a long right-hand tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_y = pd.DataFrame(\n",
    "    data={'x': fit_nc_std_norm.stan_variable('alpha_std')[: , 0],\n",
    "          'y': np.log(fit_nc_std_norm.stan_variable('sigma'))}\n",
    ")\n",
    "\n",
    "scatter_plot(df_x_y,\n",
    "         x_lab = \"alpha_std[1]: player 1 log odds of success (transformed)\",\n",
    "         y_lab = \"log(sigma): log population scale\",\n",
    "         title = \"hierarchical vs fixed param, non-centered parameterization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the value for the generated quantities variable `alpha[1]` against `log(sigma)`\n",
    "and compare it to the first plot from the centered parameterization.\n",
    "We recover the funnel shape, but now the Y axis ranges from (-12, 0) instead of (-4, 0).\n",
    "As above, as log `sigma` approaches zero the plot has a long right-hand tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_y = pd.DataFrame(\n",
    "    data={'x': fit_nc_std_norm.stan_variable('alpha')[: , 0],\n",
    "          'y': np.log(fit_nc_std_norm.stan_variable('sigma'))}\n",
    ")\n",
    "\n",
    "scatter_plot(df_x_y,\n",
    "         x_lab = \"alpha[1]: player 1 log odds of success\",\n",
    "         y_lab = \"log(sigma): log population scale\",\n",
    "         title = \"hierarchical param vs generated quantity variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still don't have enough data to determine whether or not the observed variance\n",
    "is hierarchical or individual-level variance.\n",
    "The model still provides us with an estimate for `alpha`, a player's log-odds of success at bat.\n",
    "Critically, because `alpha` is no longer a parameter variable, replaced by `alpha_std`\n",
    "in the sampling distribution, the sampler can fully explore the posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the affine transform parameterization\n",
    "\n",
    "The model `hier-logit-nc-affine-xform.stan` looks just like the centered parameterization,\n",
    "with the exception that parameter `alpha` is defined with `<offset = mu, multiplier = sigma>`.\n",
    "\n",
    "To show that the affine transform reparameterization and the standard normal reparameterization are equivalent\n",
    "we fit the model to the data and plot the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_affine_xform_model = CmdStanModel(stan_file='hier-logit-nc-affine-xform.stan')\n",
    "print(nc_affine_xform_model.code())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_nc_affine = nc_affine_xform_model.sample(\n",
    "    data=baseball_data,\n",
    "    iter_sampling=int(M/4),\n",
    "    seed=54321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we check for problems by running CmdStan's diagnose method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit_nc_affine.diagnose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Centered parameterization\")\n",
    "print(fit_centered.summary(sig_figs=3).round(decimals=3).filter(\n",
    "    [\"mu\", \"sigma\",\n",
    "     \"theta[1]\", \"theta[5]\", \"theta[10]\", \"theta[18]\",\n",
    "     \"alpha[1]\", \"alpha[5]\", \"alpha[10]\", \"alpha[18]\"],\n",
    "    axis=\"index\"))\n",
    "\n",
    "print(\"\\nNon-centered parameterization, std_normal reparameterization\")\n",
    "print(fit_nc_std_norm.summary(sig_figs=3).round(decimals=3).filter(\n",
    "    [\"mu\", \"sigma\",\n",
    "     \"theta[1]\", \"theta[5]\", \"theta[10]\", \"theta[18]\",\n",
    "     \"alpha[1]\", \"alpha[5]\", \"alpha[10]\", \"alpha[18]\"],\n",
    "    axis=\"index\"))\n",
    "\n",
    "print(\"\\nNon-centered parameterization, affine transform reparameterization\")\n",
    "print(fit_nc_affine.summary(sig_figs=3).round(decimals=3).filter(\n",
    "    [\"mu\", \"sigma\",\n",
    "     \"theta[1]\", \"theta[5]\", \"theta[10]\", \"theta[18]\",\n",
    "     \"alpha[1]\", \"alpha[5]\", \"alpha[10]\", \"alpha[18]\"],\n",
    "    axis=\"index\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the sample values for log scale and the first player ability parameter, `alpha[1]`.\n",
    "This plot is almost identical to the above plot,\n",
    "\"hierarchical vs generated quantity variable\".\n",
    "Critically, this plot differs from the first plot from the centered parameterization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_y = pd.DataFrame(\n",
    "    data={'x': fit_nc_affine.stan_variable('alpha')[: , 0],\n",
    "          'y': np.log(fit_nc_affine.stan_variable('sigma'))}\n",
    ")\n",
    "\n",
    "scatter_plot(df_x_y,\n",
    "         x_lab = \"alpha[1]: player 1 log odds of success\",\n",
    "         y_lab = \"log(sigma): log population scale\",\n",
    "         title = \"hierarchical vs fixed param, affine transform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't Panic!\n",
    "\n",
    "You may be asking: *\"but this is a funnel plot, isn't this bad?\"*\n",
    "\n",
    "The answer is: *\"no!*\n",
    "\n",
    "Stan reports the parameter estimates on the *constrained* scale,\n",
    "but it computes on the *unconstrained* scale.\n",
    "The corresponding unconstrained value for `alpha` is $\\frac{\\alpha_n - \\mu}{\\sigma}$.\n",
    "In the generated quantities block we recover this as variable `alpha_std`.\n",
    "\n",
    "Plotting `log(sigma)` against `alpha_std[1]` we see the same sampling distribution\n",
    "as in the standard normal parameterization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_y = pd.DataFrame(\n",
    "    data={'x': fit_nc_affine.stan_variable('alpha_std')[: , 0],\n",
    "          'y': np.log(fit_nc_affine.stan_variable('sigma'))}\n",
    ")\n",
    "\n",
    "scatter_plot(df_x_y,\n",
    "         x_lab = \"alpha_std[1] ==  alpha[1] unconstrained scale\",\n",
    "         y_lab = \"log(sigma): log population scale\",\n",
    "         title = \"hierarchical vs fixed param, sampling distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both `hier-logit-nc-std-norm.stan` and `hier-logit-nc-affine-xform.stan` produce essentially\n",
    "the same results; this is because both models are essentially the same model:\n",
    "they encode the non-centered parameterization.\n",
    "\n",
    "In program `hier-logit-nc-std-norm.stan`\n",
    "we define `alpha` as a transformed parameter and recover `theta`\n",
    "in the generated quantities block.\n",
    "```\n",
    "transformed parameters {\n",
    "  vector[N] alpha = mu + sigma * alpha_std;\n",
    "}\n",
    "...\n",
    "generated quantities {\n",
    "  vector[N] theta = inv_logit(mu + sigma * alpha_std);\n",
    "}\n",
    "```\n",
    "\n",
    "In program `hier-logit-nc-affine-xform.stan`\n",
    "variable `alpha` is a parameter with hierarchical prior `normal(mu, sigma)`.\n",
    "In the generated quantities block we recover `theta`,\n",
    "our estimate of a player's chance of success.\n",
    "Were there a need for it, we would be able to generate variable `alpha_std`\n",
    "as well.\n",
    "\n",
    "```\n",
    "generated quantities {\n",
    "  vector[N] theta = inv_logit(alpha);\n",
    "  vector[N] alpha_std = (alpha - mu)/sigma;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Hierarchical models where the of hierarchical prior is specified in terms\n",
    "of a location and scale\n",
    "can be parameterized in one of two ways:  centered or non-centered.\n",
    "When there are enough per-group observations, the sampler can determine\n",
    "the amount of group-level variance from the amount of individual-level variance\n",
    "and the centered parameterization is recommended.\n",
    "For smaller amounts of per-group observations, the non-centered parameterization\n",
    "is preferred.\n",
    "\n",
    "For the non-centered parameterization,\n",
    "using the affine transform makes it easier to see the hierarchical structure of the model.\n",
    "When using the affine transform, the sampler computes on the unconstrained scale\n",
    "reports the parameter value on the constrained scale.\n",
    "For this reason, using standard normal parameterization may be more computationally efficient,\n",
    "as it eleminates extra transforms, but for simple models this difference may not be noticeable.\n",
    "\n",
    "In this note we only consider models with a normal hierarchical prior,\n",
    "which can be coded either by use of the Stan language's `offset, multiplier` syntax,\n",
    "or by explicitly introducing a standardized parameter.\n",
    "Non-normal hierarchical priors are more challenging to reparameterize and are beyond the\n",
    "scope of this discussion.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
